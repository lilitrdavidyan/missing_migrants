{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab3cc431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                      # For data manipulation and analysis\n",
    "import numpy as np                       # For numerical computations\n",
    "import matplotlib.pyplot as plt          # For creating plots and visualizations\n",
    "import seaborn as sns                    # For enhanced data visualizations\n",
    "import scipy.stats as stats              # For statistical analysis\n",
    "import re                                # For regular expressions\n",
    "import logging\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83539fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c183fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path):\n",
    "    # Input validation\n",
    "    if not isinstance(file_path, str):\n",
    "        raise ValueError(\"Input 'file_path' should be a string representing the file path.\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File '{file_path}' not found.\")\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Starting data processing for {file_path}...\")\n",
    "        data = pd.read_csv(file_path)\n",
    "        logging.info(\"Data loaded successfully.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An error occurred while loading data from {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "264ca975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_data(file_path):\n",
    "    # Input validation\n",
    "    if not isinstance(file_path, str):\n",
    "        raise ValueError(\"Input 'file_path' should be a string representing the file path.\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File '{file_path}' not found.\")\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_excel(file_path)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An error occurred while loading data from {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "463d807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis_report(raw_data):\n",
    "    # Initialize an empty report dictionary to store findings and recommendations\n",
    "    report = {}\n",
    "    \n",
    "    # Check column labels and recommend converting them to snake_case\n",
    "    snake_case_columns = [col.strip().lower().replace(' ', '_').str.replace('[^\\w]', '', regex=True) for col in raw_data.columns]\n",
    "    if raw_data.columns.tolist() != snake_case_columns:\n",
    "        report['Column Labels'] = {\n",
    "            'Issue': 'Column labels are not in snake_case format',\n",
    "#             'Recommendation': f'Rename columns to snake_case format: {\", \".join(snake_case_columns)}'\n",
    "        }\n",
    "        \n",
    "    # Check for duplicate records and recommend removing duplicates\n",
    "    if raw_data.duplicated().any():\n",
    "        report['Duplicate Records'] = {\n",
    "            'Issue': 'Duplicate records exist in the data',\n",
    "            'Recommendation': 'Remove duplicate records using drop_duplicates()'\n",
    "        }\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e167b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(cleaned_data, file_path):\n",
    "    # Input validation\n",
    "    if not isinstance(cleaned_data, pd.DataFrame):\n",
    "        raise ValueError(\"Input 'cleaned_data' is not a valid DataFrame.\")\n",
    "    \n",
    "    if not isinstance(file_path, str):\n",
    "        raise ValueError(\"Input 'file_path' should be a string representing the file path.\")\n",
    "    \n",
    "    try:\n",
    "        cleaned_data.to_csv(file_path, index=False)\n",
    "        print(f\"Data saved to {file_path} successfully.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An error occurred while saving data to {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e15f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure consistency and ease of use, standardize the column names of the dataframe. \n",
    "def clean_column_names(raw_data):\n",
    "    # Input validation\n",
    "    if not isinstance(raw_data, pd.DataFrame):\n",
    "        raise ValueError(\"Input 'raw_data' is not a valid DataFrame.\")\n",
    "    \n",
    "    # Logging\n",
    "    logging.info(\"Cleaning column names...\")\n",
    "\n",
    "    # Create a defensive copy of the DataFrame\n",
    "    cleaned_data = raw_data.copy()\n",
    "    \n",
    "    # Clean column names\n",
    "    cleaned_data.columns = cleaned_data.columns.str.strip().str.replace(' ', '_').str.lower().str.replace('[^\\w]', '', regex=True)\n",
    "    \n",
    "    # Logging\n",
    "    logging.info(\"Column names cleaned.\")\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9cd0d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames the column names of the given date frame with according to the specified column_names dictionary\n",
    "# Example column_names={'st': 'state'}\n",
    "\n",
    "def rename_column_names(raw_data, column_names):\n",
    "    if not isinstance(raw_data, pd.DataFrame) or raw_data.empty:\n",
    "        raise ValueError(\"Input 'raw_data' must be a non-empty DataFrame.\")\n",
    "    \n",
    "    if not isinstance(column_names, dict):\n",
    "        raise ValueError(\"Input 'column_names' must be a dictionary.\")\n",
    "    \n",
    "    existing_columns = set(raw_data.columns)\n",
    "    \n",
    "    new_columns = set(column_names.values())\n",
    "    \n",
    "    if not new_columns.isdisjoint(existing_columns):\n",
    "        raise ValueError(\"New column names should not overlap with existing column names.\")\n",
    "    \n",
    "    for key in column_names:\n",
    "        if key not in existing_columns:\n",
    "            raise ValueError(f\"Column '{key}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    raw_data = raw_data.rename(columns=column_names)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "189b9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_numeric_column_types(data):\n",
    "    # Input validation\n",
    "    if not isinstance(data, pd.DataFrame) or data.empty:\n",
    "        raise ValueError(\"Input 'data' should be a non-empty DataFrame.\")\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_columns = data.select_dtypes(include=[int, float]).columns\n",
    "    \n",
    "    # Convert numeric columns to appropriate numeric types\n",
    "    for col in numeric_columns:\n",
    "        try:\n",
    "            data[col] = pd.to_numeric(data[col])\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Unable to convert '{col}' to numeric. It contains non-numeric values.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28255a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_and_convert_numeric_column(data, column):\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "    \n",
    "    if column not in data.columns:\n",
    "        raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    # Extract the column and remove any leading/trailing whitespaces\n",
    "    column_data = data[column].str.strip()\n",
    "    \n",
    "    # Check if all values in the column are numeric\n",
    "    if column_data.str.isnumeric().all():\n",
    "        data[column] = pd.to_numeric(column_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f613331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_and_convert_all_numeric_columns(data):\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "    \n",
    "    for column in data.columns:\n",
    "        data = identify_and_convert_numeric_column(data, column)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427a6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "405b2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with any missing values (NaN) from a pandas DataFrame.\n",
    "\n",
    "def remove_empty_raws(data):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Logging\n",
    "        logging.info(\"Removing rows with missing values (NaN)...\")\n",
    "\n",
    "        # Remove rows with all missing values (NaN)\n",
    "        data.dropna(how='all', inplace=True)\n",
    "\n",
    "        # Logging\n",
    "        logging.info(\"Rows with missing values (NaN) removed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "702b799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in specific columns.\n",
    "\n",
    "def drop_raws_with_na_values(data, columns):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Check if 'columns' is a list of valid column names in 'data'\n",
    "        invalid_columns = set(columns) - set(data.columns)\n",
    "        if invalid_columns:\n",
    "            raise ValueError(f\"Invalid columns: {invalid_columns}. The DataFrame does not have these columns.\")\n",
    "\n",
    "        # Drop rows with NA values in the specified columns\n",
    "        data.dropna(subset=columns, inplace=True)\n",
    "\n",
    "        # Return the cleaned DataFrame\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "160c892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate_rows(data, columns=None):\n",
    "    try:\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        if columns is not None and not isinstance(columns, list):\n",
    "            raise ValueError(\"Input 'columns' must be a list of column names.\")\n",
    "\n",
    "        if columns is None:\n",
    "            duplicate_rows = data[data.duplicated()]\n",
    "        else:\n",
    "            if not set(columns).issubset(data.columns):\n",
    "                missing_columns = set(columns) - set(data.columns)\n",
    "                raise ValueError(f\"Columns {missing_columns} do not exist in the DataFrame.\")\n",
    "\n",
    "            duplicate_rows = data[data.duplicated(subset=columns)]\n",
    "\n",
    "        return duplicate_rows\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a90f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows based on specific columns.\n",
    "\n",
    "def drop_duplicates(data, columns, keep):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Check if 'columns' is a list of valid column names in 'data'\n",
    "        invalid_columns = set(columns) - set(data.columns)\n",
    "        if invalid_columns:\n",
    "            raise ValueError(f\"Invalid columns: {invalid_columns}. The DataFrame does not have these columns.\")\n",
    "\n",
    "        # Check if 'keep' argument is valid\n",
    "        valid_keep_values = ['first', 'last', False]\n",
    "        if keep not in valid_keep_values:\n",
    "            raise ValueError(f\"Invalid value for 'keep': {keep}. Valid values are 'first', 'last', and False.\")\n",
    "\n",
    "        # Logging\n",
    "        logging.info(\"Dropping duplicate rows based on specific columns...\")\n",
    "\n",
    "        # Drop duplicate rows based on the specified columns and 'keep' option\n",
    "        data.drop_duplicates(subset=columns, keep=keep, inplace=True)\n",
    "\n",
    "        # Logging\n",
    "        logging.info(\"Duplicate rows dropped based on specific columns.\")\n",
    "\n",
    "        # Return the cleaned DataFrame\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "691359ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace inconsistent values with their correct counterparts\n",
    "def replace_inconsistent_values(data, column, mapping):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Check if 'column' is a valid column name in 'data'\n",
    "        if column not in data.columns:\n",
    "            raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "        # Check if 'mapping' is a dictionary\n",
    "        if not isinstance(mapping, dict):\n",
    "            raise ValueError(\"'mapping' argument must be a dictionary.\")\n",
    "\n",
    "        # Replace inconsistent values in the specified column with their correct counterparts\n",
    "        data[column] = data[column].replace(mapping)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4d43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in a specific column of a pandas DataFrame with either the mean or median.\n",
    "\n",
    "def fill_null_with_mean_or_median(data, column, method='mean'):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Check if 'column' is a valid column in the DataFrame\n",
    "        if column not in data.columns:\n",
    "            raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "        # Check if 'method' is valid\n",
    "        if method not in ['mean', 'median']:\n",
    "            raise ValueError(\"'method' must be one of 'mean' or 'median'.\")\n",
    "\n",
    "        # Get the data type of the column\n",
    "        dtype = data[column].dtype\n",
    "\n",
    "        # Check if the column is numeric (int64 or float64) for mean or median calculation\n",
    "        if dtype != 'int64' and dtype != 'float64':\n",
    "            raise ValueError(f\"Column '{column}' is not numeric (int64 or float64).\")\n",
    "\n",
    "        # Fill null values based on the specified method\n",
    "        if method == 'mean':\n",
    "            data[column].fillna(data[column].mean(), inplace=True)\n",
    "        elif method == 'median':\n",
    "            data[column].fillna(data[column].median(), inplace=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89c21d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in a pandas DataFrame with appropriate values based on column data types.\n",
    "\n",
    "\n",
    "def fill_all_null_values(data):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Loop through each column\n",
    "        for col in data.columns:\n",
    "            # Get the data type of the column\n",
    "            dtype = data[col].dtype\n",
    "\n",
    "            # Fill null values based on data type\n",
    "            if dtype == 'object':\n",
    "                data[col].fillna(data[col].mode()[0], inplace=True)  # Fill with mode\n",
    "            elif dtype == 'int64' or dtype == 'float64':\n",
    "                data[col].fillna(data[col].mean(), inplace=True)     # Fill with mean\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bebf4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_with_previous_or_next_value(data, column, method='previous'):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Check if 'column' is a valid column in the DataFrame\n",
    "        if column not in data.columns:\n",
    "            raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "        # Check if 'method' is valid\n",
    "        if method not in ['previous', 'next']:\n",
    "            raise ValueError(\"'method' must be one of 'previous' or 'next'.\")\n",
    "\n",
    "        # Fill null values based on the specified method\n",
    "        if method == 'previous':\n",
    "            data[column].fillna(method='ffill', inplace=True)\n",
    "        elif method == 'next':\n",
    "            data[column].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "125d2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls_in_dataset_with_previous_or_next(data, method='previous'):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Check if 'method' is valid\n",
    "        if method not in ['previous', 'next']:\n",
    "            raise ValueError(\"'method' must be one of 'previous' or 'next'.\")\n",
    "\n",
    "        # Iterate through each column and fill null values with the specified method\n",
    "        for column in data.columns:\n",
    "            fill_null_with_previous_or_next_value(data, column, method=method)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0dd5cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are null values in a pandas DataFrame and return the list of columns with null values.\n",
    "\n",
    "def check_null_values(data):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Get the list of columns with null values\n",
    "        columns_with_nulls = data.columns[data.isnull().any()].tolist()\n",
    "\n",
    "        return columns_with_nulls\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a40520a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows from a pandas DataFrame that have null values in the specified list of columns.\n",
    "# If the 'columns' list is empty, it will consider all columns for checking null values.\n",
    "\n",
    "def get_rows_with_null_values(data, columns=[]):\n",
    "    try:\n",
    "        # Check if 'data' is a pandas DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n",
    "\n",
    "        # Check if 'columns' is a list\n",
    "        if not isinstance(columns, list):\n",
    "            raise ValueError(\"Input 'columns' must be a list of column names.\")\n",
    "\n",
    "        # If 'columns' is empty, consider all columns for checking null values\n",
    "        if not columns:\n",
    "            rows_with_nulls = data[data.isnull().any(axis=1)]\n",
    "        else:\n",
    "            rows_with_nulls = data[data[columns].isnull().any(axis=1)]\n",
    "\n",
    "        return rows_with_nulls\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and provide informative error messages\n",
    "        raise ValueError(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0b0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cfcddd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data):\n",
    "    logging.info(f\"Starting cleaning data...\")\n",
    "    \n",
    "    raw_data = clean_column_names(raw_data)\n",
    "    remove_empty_raws(raw_data)\n",
    "    #raw_data = drop_duplicates(raw_data)\n",
    "    logging.info(f\"Data cleaning completed.\")\n",
    "    \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1980179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a string is in snake_case format\n",
    "def is_snake_case(string):\n",
    "    return re.match(r'^[a-z_][a-z0-9_]*$', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f63f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to detect outliers using the z-score method\n",
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "    return z_scores > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1456238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the majority data type for a column\n",
    "def identify_data_type(column_values):\n",
    "    # Create a Series from the column values\n",
    "    series = pd.Series(column_values)\n",
    "\n",
    "    # Get the data type counts using value_counts()\n",
    "    data_type_counts = series.apply(type).value_counts()\n",
    "\n",
    "    # Get the majority data type\n",
    "    majority_data_type = data_type_counts.idxmax().__name__\n",
    "    \n",
    "    return majority_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bdb4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the list of columns with inconsistent data types\n",
    "def identify_inconsistent_data_types(df):\n",
    "    remove_empty_raws(df)\n",
    "    inconsistent_columns = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Get the data type counts using value_counts()\n",
    "        data_type_counts = series.apply(type).value_counts()\n",
    "        \n",
    "        # Get the majority data type\n",
    "        majority_data_type = data_type_counts.idxmax()\n",
    "        \n",
    "        # Check if the majority data type is different from the actual column data type\n",
    "        if majority_data_type != type(series.iloc[0]):\n",
    "            inconsistent_columns[col] = majority_data_type\n",
    "\n",
    "    return inconsistent_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6a4bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis_report(raw_data):\n",
    "    # Initialize an empty report dictionary to store findings and recommendations\n",
    "    report = {}\n",
    "    \n",
    "    # Basic check: Is the dataset empty?\n",
    "    if raw_data.empty:\n",
    "        report['Empty Dataset'] = {\n",
    "            'issue': 'The dataset is empty',\n",
    "            'recommendation': 'Check the data source and load the dataset properly'\n",
    "        }\n",
    "        return report\n",
    "    \n",
    "    # Check column labels and recommend converting them to snake_case\n",
    "    non_snake_case_columns = [col for col in raw_data.columns if not is_snake_case(col)]\n",
    "    if non_snake_case_columns:\n",
    "        report['Non-Snake Case Columns'] = {\n",
    "            'columns': non_snake_case_columns,\n",
    "            'count': len(non_snake_case_columns),\n",
    "            'issue': 'Column labels are not in snake_case format',\n",
    "            'recommendation': f'Rename columns to snake_case format: {\", \".join(non_snake_case_columns)}'\n",
    "        }\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    duplicates = raw_data.duplicated()\n",
    "    if duplicates.any():\n",
    "        report['Duplicate Rows'] = {\n",
    "            'count': duplicates.sum(),\n",
    "            'issue': 'Duplicate rows found in the dataset',\n",
    "            'recommendation': 'Remove or handle duplicate rows appropriately'\n",
    "        }\n",
    "    \n",
    "    # Check for missing values in each column\n",
    "    missing_values_check = raw_data.isnull().sum()\n",
    "    if missing_values_check.any():\n",
    "        columns_with_missing_values = missing_values_check[missing_values_check > 0].index.tolist()\n",
    "        report['Missing Values'] = {\n",
    "            'columns': columns_with_missing_values,\n",
    "            'count': missing_values_check.to_dict(),\n",
    "            'issue': 'Missing values found in the dataset',\n",
    "            'recommendation': 'Remove or impute missing values'\n",
    "        }\n",
    "        \n",
    "    \n",
    "    # Check for outliers in numerical columns\n",
    "    numerical_columns = raw_data.select_dtypes(include=[np.number]).columns\n",
    "    outliers_columns = []\n",
    "    for numerical_column in numerical_columns:\n",
    "        outliers_check = detect_outliers_zscore(raw_data[numerical_column])\n",
    "        \n",
    "        if outliers_check.any():\n",
    "            outliers_columns.append(numerical_column)\n",
    "            \n",
    "    if outliers_columns:\n",
    "        report['Outliers Detected'] = {\n",
    "            'columns': outliers_columns,\n",
    "            'count': len(outliers_columns),\n",
    "            'issue': 'Outliers detected in the dataset',\n",
    "            'recommendation': 'Handle outliers appropriately (e.g., remove or transform)'\n",
    "        }\n",
    "            \n",
    "    # Check data types of columns\n",
    "    inconsistent_data_types = identify_inconsistent_data_types(raw_data)\n",
    "    \n",
    "    report['Incorrect Data Types'] = {\n",
    "        'columns': inconsistent_data_types,\n",
    "        'count': len(inconsistent_data_types),\n",
    "        'issue': 'Inconsistent or incorrect data types',\n",
    "        'recommendation': 'Ensure data types are appropriate and consistent'\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame.from_dict(report, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cb17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9debe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
